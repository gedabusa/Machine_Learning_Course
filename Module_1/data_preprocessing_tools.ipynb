{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gedabusa/Machine_Learning_Course/blob/master/Module_1/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF0C0IZIH3de",
        "colab_type": "text"
      },
      "source": [
        "In this first step, we import all libraries used for loading dataset, ploting results and handling data. Pandas loads data from files as .csv, .json and databases. Numpy handles dataframes and Matplotlib creates plot with transfomed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDtgFoTKR08n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxtiZhi0K5Il",
        "colab_type": "text"
      },
      "source": [
        "Data.csv is a file with 4 columns that specifies the purchases in a site. In 3 first columns, we find independent variables, as country where client purchased from, age and salary from it. The last one is a flag whether or not the client purchased the product.\n",
        "\n",
        "Using function __iloc__, we can slice the dataset, knowing the column order and the dependence between them. the result is two vectors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSNrUXcOSBZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"Data.csv\")\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqdlf7mBUn_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "f87d248c-c8c4-4fc6-9892-c822fb3f80a5"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9iqFP1kU4KJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c696353b-db8c-4502-ac92-ab31f78d8ca7"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dPVj8b6TMU0",
        "colab_type": "text"
      },
      "source": [
        "If you let the data as they are saved in the dataset, if could gerate errors in your machine learning model. There are many approaches how to lead with null and missing data in your dataset. You can modify the value for some statistical measure, remove data from dataset or put in zero.\n",
        "\n",
        "_Sklearn_ already uses functions to modify values into dataset. In this example, we are going to replace missing values for mean itself. In order to aplly on the datset, we must call transformation function. The implementation can be done separately, first calling fit function to calcule mean and then calling transformation function to do it inside dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jsx2nG_nRPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRR-1dQ0sAGk",
        "colab_type": "text"
      },
      "source": [
        "The simplest implementation to use string values is to transform them in numeric values. It can be realized converting classes in columns. for example, for country column, we find three diferents countries. we can change \n",
        "the first country by zero, the second one by one and the last one by two. the problem of using that concept is our model would assume the data like a order list instead of a classification.\n",
        "\n",
        "The best approach is to create one column by each existent country and then we fill the columns up with binary value. For example, for France will have the vector [1 0 0], for Spain [0 1 0] and for Germany [0 0 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLX1vBjc0ckP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0])], remainder= 'passthrough')\n",
        "# type of transformation\n",
        "# kind of transformation\n",
        "\n",
        "# Remainder... To keep the columns in the dataset\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB0GrsPz2fpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "71bc9682-4335-4cbf-cb0b-946c2c0b870f"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnY7xWCn20_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyhY8-gPpFCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29751a57-481a-490d-a097-53e13f4ad205"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm0BzNaM5SJX",
        "colab_type": "text"
      },
      "source": [
        "We are going to split our dataset into the training dataset and test dataset. we will be training dataset to train our model, estimating standard deviation with the training output dataset. The test dataset will be used to test if our model is able to estimate the test output set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXgA6CzlqbCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuwQhFdKrYTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "07a208f3-8e81-4fdd-ee05-636a1446689c"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUrX_Tvcrbi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "98836748-2733-47b5-9131-adc7c7dbe5b7"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSMHiIsWreQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a51384c-8f6e-43fc-b0dd-c4ddb65f735f"
      },
      "source": [
        "print(Y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_tW7H56rgtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0db2dbfd-b6f4-4692-d200-98f6d6f78d53"
      },
      "source": [
        "print(Y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxjSUXFQqo-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPET8ZdlMnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTXykB_QlRjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}